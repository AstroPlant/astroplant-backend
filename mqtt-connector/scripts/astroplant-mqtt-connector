#!/usr/bin/env python

import os
import logging
import click
import datetime


def utc_from_millis(t):
    return datetime.datetime.fromtimestamp(t / 1000, datetime.timezone.utc)


def _setup_listener():
    from astroplant_mqtt_connector.mqtt_listener import MqttListener

    return MqttListener(
        host=os.environ.get("MQTT_HOST", "localhost"),
        port=int(os.environ.get("MQTT_PORT", "1883")),
        username=os.environ.get("MQTT_USERNAME", "server"),
        password=os.environ.get("MQTT_PASSWORD", ""),
    )


@click.group()
def cli():
    pass


@cli.command()
def version():
    from astroplant_mqtt_connector import __version__

    print(__version__)


@cli.command()
def to_database():
    from uuid import UUID
    import astroplant_database.specification as d

    db = d.DatabaseManager(
        os.environ.get(
            "DATABASE_URL",
            "postgresql+psycopg2://astroplant:astroplant@localhost/astroplant",
        )
    )

    listener = _setup_listener()
    listener.start()

    while True:
        (message_type, message, message_id) = listener.message_queue.get()

        kit = db.Session.query(d.Kit).filter(d.Kit.serial == message.kitSerial).one()
        peripheral = (
            db.Session.query(d.Peripheral)
            .filter(d.Peripheral.id == message.peripheral)
            .filter(d.Peripheral.kit_id == kit.id)
            .one()
        )

        if not kit or not peripheral:
            logger.warning(f"Kit or peripheral not found for message {message_id}")
            continue

        measurement = None
        if message_type == "raw":
            measurement = d.RawMeasurement(
                id=UUID(bytes=message.id),
                kit=kit,
                kit_configuration=peripheral.kit_configuration,
                peripheral=peripheral,
                quantity_type_id=message.quantityType,
                value=message.value,
                datetime=utc_from_millis(message.datetime),
            )
        elif message_type == "aggregate":
            values = {
                aggregate.type: aggregate.value
                for aggregate in message.values
                if 0 < len(aggregate.type) <= 50
            }

            if 0 < len(values) <= 16:
                measurement = d.AggregateMeasurement(
                    id=UUID(bytes=message.id),
                    kit=kit,
                    kit_configuration=peripheral.kit_configuration,
                    peripheral=peripheral,
                    quantity_type_id=message.quantityType,
                    datetime_start=utc_from_millis(message.datetimeStart),
                    datetime_end=utc_from_millis(message.datetimeEnd),
                    values=values,
                )
        db.Session.add(measurement)
        try:
            db.Session.commit()
            logger.debug(f"Measurement {message_id} committed to database.")
        except:
            logger.debug(f"Error while committing message {message_id} to database.")
            db.Session.rollback()


@cli.command()
def to_kafka():
    from kafka import KafkaProducer

    listener = _setup_listener()
    listener.start()

    logger.debug("Creating Kafka producer.")
    kafka_host = os.environ.get("KAFKA_HOST", "localhost")
    kafka_port = os.environ.get("KAFKA_PORT", "9092")
    kafka_username = os.environ.get("KAFKA_USERNAME")
    kafka_password = os.environ.get("KAFKA_PASSWORD")

    logger.info(f"Kafka bootstrapping to {kafka_host}:{kafka_port}.")
    kafka_producer = KafkaProducer(
        bootstrap_servers=f"{kafka_host}:{kafka_port}",
        client_id="astroplant-mqtt-kafka-connector",
        acks=1,  # Topic leader must acknowledge our messages.
        security_protocol="SASL_PLAINTEXT" if kafka_username else "PLAINTEXT",
        sasl_mechanism="PLAIN" if kafka_username else None,
        sasl_plain_username=kafka_username,
        sasl_plain_password=kafka_password,
    )

    # Define inline function to avoid capture issues in lambdas.
    def _send(message_type, message, message_id):
        result = kafka_producer.send(
            topic=message_type, value=message.to_bytes_packed(),
        )
        result.add_callback(
            lambda res: logger.debug(
                f"Message {message_id}: successfully sent to Kafka. "
                f"Partition: {res.partition}. "
                f"Offset: {res.offset}."
            )
        )
        result.add_errback(
            lambda err: logger.warning(
                f"Message {message_id} could not be sent to Kafka: {err}"
            )
        )

    while True:
        (message_type, message, message_id) = listener.message_queue.get()
        _send(message_type, message, message_id)


if __name__ == "__main__":
    logger = logging.getLogger("astroplant_mqtt_connector")
    logger.setLevel(logging.DEBUG)

    ch = logging.StreamHandler()
    ch.setLevel(logging.getLevelName(os.environ.get("LOG_LEVEL", "INFO")))

    formatter = logging.Formatter(
        "%(asctime)s - %(threadName)s - %(name)s - %(levelname)s - %(message)s"
    )

    ch.setFormatter(formatter)
    logger.addHandler(ch)

    cli()
